{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fM4QPaycPlic",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "b1b3521c-cfb7-4362-b1d5-990f7c3739a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!python -m spacy download en_core_web_trf\\n\\n!pip install paddlepaddle-gpu==2.3.0.post110 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html\\n#!python3 -m pip install paddlepaddle-gpu==2.0.2 -f https://paddlepaddle.org.cn/whl/stable/noavx.html\\n!pip install pdf2image\\n!apt-get update\\n!apt-get install poppler-utils\\n\\n######Dont install#!python3 -m pip install paddlepaddle-gpu\\n!python -m pip install --force-reinstall paddlepaddle==2.5\\n\\n!pip install \"paddleocr>=2.0.1\"\\n#!pip install protobuf==3.20.0\\n!git clone https://github.com/PaddlePaddle/PaddleOCR.git\\n\\n!wget https://paddleocr.bj.bcebos.com/whl/layoutparser-0.0.0-py3-none-any.whl\\n!pip install -U layoutparser-0.0.0-py3-none-any.whl\\n\\n### Install first one if code doea not work install others\\n!pip install protobuf==3.20.*\\n#!pip install -U layoutparser-0.0.0-py3-none-any.whl\\n#!wget https://www.openssl.org/source/openssl-1.1.1o.tar.gz\\n#!wget http://nz2.archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1f-1ubuntu2_amd64.deb\\n#!sudo dpkg -i libssl1.1_1.1.1f-1ubuntu2_amd64.deb\\n\\n!wget https://www.openssl.org/source/openssl-1.1.1o.tar.gz\\n!wget http://nz2.archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1f-1ubuntu2_amd64.deb\\n!sudo dpkg -i libssl1.1_1.1.1f-1ubuntu2_amd64.deb'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "'''!python -m spacy download en_core_web_trf\n",
        "\n",
        "!pip install paddlepaddle-gpu==2.3.0.post110 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html\n",
        "#!python3 -m pip install paddlepaddle-gpu==2.0.2 -f https://paddlepaddle.org.cn/whl/stable/noavx.html\n",
        "!pip install pdf2image\n",
        "!apt-get update\n",
        "!apt-get install poppler-utils\n",
        "\n",
        "######Dont install#!python3 -m pip install paddlepaddle-gpu\n",
        "!python -m pip install --force-reinstall paddlepaddle==2.5\n",
        "\n",
        "!pip install \"paddleocr>=2.0.1\"\n",
        "#!pip install protobuf==3.20.0\n",
        "!git clone https://github.com/PaddlePaddle/PaddleOCR.git\n",
        "\n",
        "!wget https://paddleocr.bj.bcebos.com/whl/layoutparser-0.0.0-py3-none-any.whl\n",
        "!pip install -U layoutparser-0.0.0-py3-none-any.whl\n",
        "\n",
        "### Install first one if code doea not work install others\n",
        "!pip install protobuf==3.20.*\n",
        "#!pip install -U layoutparser-0.0.0-py3-none-any.whl\n",
        "#!wget https://www.openssl.org/source/openssl-1.1.1o.tar.gz\n",
        "#!wget http://nz2.archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1f-1ubuntu2_amd64.deb\n",
        "#!sudo dpkg -i libssl1.1_1.1.1f-1ubuntu2_amd64.deb\n",
        "\n",
        "!wget https://www.openssl.org/source/openssl-1.1.1o.tar.gz\n",
        "!wget http://nz2.archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1f-1ubuntu2_amd64.deb\n",
        "!sudo dpkg -i libssl1.1_1.1.1f-1ubuntu2_amd64.deb'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import spacy\n",
        "import spacy_transformers\n",
        "\n",
        "import cv2\n",
        "import layoutparser as lp\n",
        "\n",
        "from paddleocr import PaddleOCR, draw_ocr\n",
        "\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "import os\n",
        "import glob\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "Z-YeqJWPPrUv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to check if a string matches the GSTIN pattern\n",
        "def is_valid_gstin(gstin):\n",
        "  # Define the GSTIN pattern\n",
        "  gstin_pattern = r'^[0-9]{2}[A-Z]{5}[0-9]{4}[A-Z]{1}[0-9]{1}[A-Z]{1}[A-Z0-9]{1}$'\n",
        "  return bool(re.match(gstin_pattern, gstin))\n",
        "\n",
        "# Function to check if a string matches any of the specified date formats\n",
        "def is_valid_date_time(date_time_str):\n",
        "  # Define a list of date formats to check\n",
        "  date_formats = [\"%d.%m.%y%H:%M:%S\", \"%Y-%m-%d %H:%M:%S\", \"%Y-%m-%d\", \"%d/%m/%Y\", \"%m/%d/%Y\"]\n",
        "  for date_format in date_formats:\n",
        "      try:\n",
        "          datetime.strptime(date_time_str, date_format)\n",
        "          return True\n",
        "      except ValueError:\n",
        "          continue\n",
        "  return False\n",
        "\n",
        "# Function to check if a string matches any of the invoice formats\n",
        "def is_valid_invoice(invoice_str):\n",
        "  # Define regular expressions for the invoice formats\n",
        "  invoice_patterns = [\n",
        "    r'^[A-Z]+-\\d{4}-\\d{5}$',         # Format 1: SBCC-2324-02446\n",
        "    r'^[A-Z]{2}-\\d{4}-\\d{5}$',      # Format 2: EN-2324-03793\n",
        "    r'^[A-Z]\\d+/\\d{2}-\\d{2}$'       # Format 3: S03677/23-24\n",
        "    ]\n",
        "  for pattern in invoice_patterns:\n",
        "      if re.match(pattern, invoice_str):\n",
        "          return True\n",
        "  return False\n",
        "\n",
        "def supplier_name(input_string):\n",
        "  if \"BHAGYALAKSHM\" in input_string:\n",
        "    return \"SRI BHAGYALAKSHMI ENTERPRISES\"\n",
        "\n",
        "def capture_tax_info():\n",
        "  boxes1 = []\n",
        "  texts1 = []\n",
        "  probabilities1 = []\n",
        "  flag = False\n",
        "  for c, line in enumerate(output):\n",
        "    if \"Tax Invoice\" in line[1][0]:\n",
        "      flag = True\n",
        "    if flag == True:\n",
        "      boxes1.append(line[0])\n",
        "      texts1.append(line[1][0])\n",
        "      probabilities1.append(line[1][1])\n",
        "    if \"S.No\" in line[1][0]:\n",
        "      flag = False\n",
        "  invoice_number = \"\"\n",
        "  invoice_date = \"\"\n",
        "  GST_Number = \"\"\n",
        "  Supplier_Name = \"\"\n",
        "  GST_flag = True\n",
        "  for line in texts1:\n",
        "\n",
        "    if line.startswith(\"GSTIN\"):\n",
        "      tt = line.split(\":\")\n",
        "      tt = tt[-1]\n",
        "      print(tt)\n",
        "      if GST_flag == True:\n",
        "        if is_valid_gstin(tt):\n",
        "          GST_Number = tt\n",
        "          GST_flag = False\n",
        "    elif GST_flag == True:\n",
        "        if is_valid_gstin(line):\n",
        "          GST_Number = line\n",
        "    if is_valid_invoice(line):\n",
        "      invoice_number = line\n",
        "    if is_valid_date_time(line):\n",
        "      invoice_date = line\n",
        "    if \"BHAGYALAKSHM\" in line:\n",
        "      Supplier_Name = \"SRI BHAGYALAKSHMI ENTERPRISES\"\n",
        "\n",
        "  return invoice_number,invoice_date,GST_Number,Supplier_Name\n",
        "\n",
        "def capture_product_info():\n",
        "  boxes = []\n",
        "  texts = []\n",
        "  probabilities = []\n",
        "  flag = False\n",
        "  tcs_flag = False\n",
        "  TCS = \"\"\n",
        "  for c, line in enumerate(output):\n",
        "    if \"S.No\" in line[1][0]:\n",
        "      flag = True\n",
        "    if flag == True:\n",
        "      boxes.append(line[0])\n",
        "      texts.append(line[1][0])\n",
        "      probabilities.append(line[1][1])\n",
        "    if \"Final Total\" in line[1][0]:\n",
        "      flag = False\n",
        "    if tcs_flag == True:\n",
        "      TCS = line[1][0]\n",
        "      tcs_flag = False\n",
        "    if \"TCS\" in line[1][0]:\n",
        "      tcs_flag = True\n",
        "  return TCS,boxes,texts,probabilities"
      ],
      "metadata": {
        "id": "XVyfaVpBc8KY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9an1hJtBQBmH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def intersection(box_1, box_2):\n",
        "  return [box_2[0], box_1[1],box_2[2], box_1[3]]\n",
        "\n",
        "def iou(box_1, box_2):\n",
        "\n",
        "  x_1 = max(box_1[0], box_2[0])\n",
        "  y_1 = max(box_1[1], box_2[1])\n",
        "  x_2 = min(box_1[2], box_2[2])\n",
        "  y_2 = min(box_1[3], box_2[3])\n",
        "\n",
        "  inter = abs(max((x_2 - x_1, 0)) * max((y_2 - y_1), 0))\n",
        "  if inter == 0:\n",
        "      return 0\n",
        "\n",
        "  box_1_area = abs((box_1[2] - box_1[0]) * (box_1[3] - box_1[1]))\n",
        "  box_2_area = abs((box_2[2] - box_2[0]) * (box_2[3] - box_2[1]))\n",
        "\n",
        "  return inter / float(box_1_area + box_2_area - inter)\n",
        "\n",
        "def draw_horizonatl_lines(cv2,image_cv,invoice_number,invoice_date,GST_Number,Supplier_Name,tcs,ext_name,boxes,texts,probabilities,output_filename):\n",
        "  image_boxes = image_cv.copy()\n",
        "\n",
        "  for box,text in zip(boxes,texts):\n",
        "    cv2.rectangle(image_boxes, (int(box[0][0]),int(box[0][1])), (int(box[2][0]),int(box[2][1])),(0,0,255),1)\n",
        "    cv2.putText(image_boxes, text,(int(box[0][0]),int(box[0][1])),cv2.FONT_HERSHEY_SIMPLEX,1,(222,0,0),1)\n",
        "\n",
        "  cv2.imwrite(\"detections\"+ext_name+\".jpg\", image_boxes)\n",
        "\n",
        "  im = image_cv.copy()\n",
        "\n",
        "  horiz_boxes = []\n",
        "  vert_boxes = []\n",
        "\n",
        "  for box in boxes:\n",
        "    x_h, x_v = 0,int(box[0][0])\n",
        "    y_h, y_v = int(box[0][1]),0\n",
        "    width_h,width_v = image_width, int(box[2][0]-box[0][0])\n",
        "    height_h,height_v = int(box[2][1]-box[0][1]),image_height\n",
        "\n",
        "    horiz_boxes.append([x_h,y_h,x_h+width_h,y_h+height_h])\n",
        "    vert_boxes.append([x_v,y_v,x_v+width_v,y_v+height_v])\n",
        "\n",
        "    cv2.rectangle(im,(x_h,y_h), (x_h+width_h,y_h+height_h),(0,0,255),1)\n",
        "    cv2.rectangle(im,(x_v,y_v), (x_v+width_v,y_v+height_v),(0,255,0),1)\n",
        "  #horiz_boxes = tf.squeeze(horiz_boxes)\n",
        "  #score_threshold = tf.squeeze(score_threshold)\n",
        "  print(horiz_boxes)\n",
        "  cv2.imwrite(\"horiz_vert\"+ext_name+\".jpg\",im)\n",
        "  print(\"before\")\n",
        "  \"\"\"\n",
        "  SCRIPT IS FAILING \"horiz_boxes\" VARIABLE RETURNING NULL VALUES AS IT IS NOT ABLE TO DRAW VERTICAL LINES TO THE horiz_vertSample71.pdf.jpg FILE\n",
        "  \"\"\"\n",
        "  horiz_out = tf.image.non_max_suppression(\n",
        "    horiz_boxes,\n",
        "    probabilities,\n",
        "    max_output_size = 1000,\n",
        "    iou_threshold=0.1,\n",
        "    #score_threshold=float('-inf'),\n",
        "    name=None\n",
        "    )\n",
        "  print(\"after\")\n",
        "  horiz_lines = np.sort(np.array(horiz_out))\n",
        "\n",
        "  im_nms = image_cv.copy()\n",
        "\n",
        "  for val in horiz_lines:\n",
        "    cv2.rectangle(im_nms, (int(horiz_boxes[val][0]),int(horiz_boxes[val][1])), (int(horiz_boxes[val][2]),int(horiz_boxes[val][3])),(0,0,255),1)\n",
        "\n",
        "  cv2.imwrite(\"im_nms\"+ext_name+\".jpg\",im_nms)\n",
        "  vert_boxes = tf.squeeze(vert_boxes)\n",
        "  vert_out = tf.image.non_max_suppression(\n",
        "    vert_boxes,\n",
        "    probabilities,\n",
        "    max_output_size = 1000,\n",
        "    iou_threshold=0.1,\n",
        "    #score_threshold=float('-inf'),\n",
        "    name=None\n",
        "    )\n",
        "\n",
        "  vert_lines = np.sort(np.array(vert_out))\n",
        "\n",
        "  for val in vert_lines:\n",
        "    cv2.rectangle(im_nms, (int(vert_boxes[val][0]),int(vert_boxes[val][1])), (int(vert_boxes[val][2]),int(vert_boxes[val][3])),(255,0,0),1)\n",
        "\n",
        "  cv2.imwrite(\"im_nms\"+ext_name+\".jpg\",im_nms)\n",
        "\n",
        "  out_array = [[\"\" for i in range(len(vert_lines))] for j in range(len(horiz_lines))]\n",
        "\n",
        "  unordered_boxes = []\n",
        "\n",
        "  for i in vert_lines:\n",
        "    #print(vert_boxes[i])\n",
        "    unordered_boxes.append(vert_boxes[i][0])\n",
        "\n",
        "  ordered_boxes = np.argsort(unordered_boxes)\n",
        "\n",
        "  for i in range(len(horiz_lines)):\n",
        "    for j in range(len(vert_lines)):\n",
        "      resultant = intersection(horiz_boxes[horiz_lines[i]], vert_boxes[vert_lines[ordered_boxes[j]]] )\n",
        "\n",
        "      for b in range(len(boxes)):\n",
        "        the_box = [boxes[b][0][0],boxes[b][0][1],boxes[b][2][0],boxes[b][2][1]]\n",
        "        if(iou(resultant,the_box)>0.1):\n",
        "          out_array[i][j] = texts[b]\n",
        "  indices = [index for index, item in enumerate(out_array) if \"Description of Goods\" in item]\n",
        "\n",
        "  indices_start = [index for index, item in enumerate(out_array) if \"PRODUCT DESCRIPTION\" in item or \"Description of Goods\" in item]\n",
        "  indices_end = [index for index, item in enumerate(out_array) if \"Total\" in item or \"Totai\" in item]\n",
        "  #indices_end = np.where(out_array == \"Total\")[0]\n",
        "  print(out_array)\n",
        "  print(indices_start)\n",
        "  print(indices_end)\n",
        "  out_array1=np.array(out_array[indices_start[0]:indices_end[0]])\n",
        "\n",
        "\n",
        "  df1 = pd.DataFrame(data = out_array1[1:, 1:],index = out_array1[1:, 0],columns = out_array1[0, 1:])\n",
        "  df1 = df1.loc[:, df1.columns != '']\n",
        "  df1.columns = ['PRODUCT DESCRIPTION', 'HSN/SAC', 'Qty.', 'Unit Rate', 'GST (%)', 'GST Amt', 'Amount']\n",
        "  df1.replace('', np.nan, inplace=True)\n",
        "  df1 = df1.dropna(how='all')\n",
        "  df1 = df1[df1['HSN/SAC'] != 'SAC']\n",
        "  df1.insert(0, 'GST_Number', GST_Number)\n",
        "  df1.insert(0, 'invoice_date', invoice_date)\n",
        "  df1.insert(0, 'invoice_number', invoice_number)\n",
        "  df1.insert(0, 'Supplier_Name', Supplier_Name)\n",
        "  #df1['TCS'] = [''] * (len(df1)-1) + [tcs]\n",
        "  df1['TCS'] = None\n",
        "  if tcs is not None:\n",
        "    df1.at[df1.index[-1], 'TCS'] = tcs\n",
        "  else:\n",
        "    df1.at[df1.index[-1], 'TCS'] = None\n",
        "\n",
        "  file_path = Path(output_filename)\n",
        "  if file_path.exists():\n",
        "    df1.to_csv(file_path, index = False, header=False, mode='a')\n",
        "  else:\n",
        "    df1.to_csv(file_path, index = False, header=True, mode='w')\n",
        "\n",
        "  #df1.to_csv('sample3d2.csv',index = False)"
      ],
      "metadata": {
        "id": "Hp5alj8xc8VK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory_path = \"/content/data\"  # Change this to the path of your directory\n",
        "output_filename = \"/content/sample_15102023.csv\"\n",
        "\n",
        "# List all files in the directory\n",
        "file_list = glob.glob(os.path.join(directory_path, \"*\"))\n",
        "\n",
        "# Iterate through the list of files\n",
        "for file_path in file_list:\n",
        "  images = convert_from_path(file_path)\n",
        "  !mkdir pages\n",
        "\n",
        "  split_result = file_path.split(\"/\")\n",
        "  print(split_result[-1])\n",
        "  print(type(split_result[-1]))\n",
        "  for i in range(len(images)):\n",
        "    images[i].save(\"pages/page\"+split_result[-1]+str(i)+\".jpg\", \"JPEG\")\n",
        "  image = cv2.imread(\"/content/pages/page\"+split_result[-1]+str(0)+\".jpg\")\n",
        "\n",
        "  image = image[..., ::-1]\n",
        "\n",
        "  # load model\n",
        "  model = lp.PaddleDetectionLayoutModel(config_path=\"lp://PubLayNet/ppyolov2_r50vd_dcn_365e_publaynet/config\",\n",
        "                                  threshold=0.5,\n",
        "                                  label_map={0:\"Text\", 1:\"Title\", 2:\"List\", 3:\"Table\", 4:\"Figure\"},\n",
        "                                  enforce_cpu=False,\n",
        "                                  enable_mkldnn=True)#math kernel library\n",
        "  # detect\n",
        "  layout = model.detect(image)\n",
        "  x_1=0\n",
        "  y_1=0\n",
        "  x_2=0\n",
        "  y_2=0\n",
        "  for l in layout:\n",
        "    #print(l)\n",
        "    if l.type == 'Figure':\n",
        "      x_1 = int(l.block.x_1)\n",
        "      #print(l.block.x_1)\n",
        "      y_1 = int(l.block.y_1)\n",
        "      x_2 = int(l.block.x_2)\n",
        "      y_2 = int(l.block.y_2)\n",
        "\n",
        "      break\n",
        "  im = cv2.imread(\"/content/pages/page\"+split_result[-1]+str(0)+\".jpg\")\n",
        "  cv2.imwrite(\"ext_im\"+split_result[-1]+\".jpg\", im[y_1:y_2,x_1:x_2])\n",
        "  ocr = PaddleOCR(lang='en')\n",
        "  image_path = \"/content/ext_im\"+split_result[-1]+\".jpg\"\n",
        "  image_cv = cv2.imread(image_path)\n",
        "  image_height = image_cv.shape[0]\n",
        "  image_width = image_cv.shape[1]\n",
        "  output = ocr.ocr(image_path)[0]\n",
        "  invoice_number,invoice_date,GST_Number,Supplier_Name = capture_tax_info()\n",
        "  tcs,boxes,texts,probabilities = capture_product_info()\n",
        "  draw_horizonatl_lines(cv2,image_cv,invoice_number,invoice_date,GST_Number,Supplier_Name,tcs,split_result[-1],boxes,texts,probabilities,output_filename)"
      ],
      "metadata": {
        "id": "sVLAMNRuPugk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "outputId": "9d581e6d-309e-4baa-bcc1-6210d7f1deb9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample71.pdf\n",
            "<class 'str'>\n",
            "download https://paddle-model-ecology.bj.bcebos.com/model/layout-parser/ppyolov2_r50vd_dcn_365e_publaynet.tar to /root/.paddledet/inference_model/ppyolov2_r50vd_dcn_365e_publaynet/ppyolov2_r50vd_dcn_365e_publaynet_infer/ppyolov2_r50vd_dcn_365e_publaynet.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 221M/221M [00:29<00:00, 7.60MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_det_infer.tar to /root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer/en_PP-OCRv3_det_infer.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.00M/4.00M [00:14<00:00, 276kiB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download https://paddleocr.bj.bcebos.com/PP-OCRv4/english/en_PP-OCRv4_rec_infer.tar to /root/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer/en_PP-OCRv4_rec_infer.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10.2M/10.2M [00:17<00:00, 594kiB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar to /root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer/ch_ppocr_mobile_v2.0_cls_infer.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.19M/2.19M [00:13<00:00, 161kiB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023/12/04 16:08:06] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/root/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/usr/local/lib/python3.10/dist-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='/root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023/12/04 16:08:07] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n",
            "[2023/12/04 16:08:08] ppocr DEBUG: dt_boxes num : 177, elapsed : 1.0256547927856445\n",
            "[2023/12/04 16:08:37] ppocr DEBUG: rec_res num  : 177, elapsed : 29.151111125946045\n",
            "29AAPPN7598F1ZS\n",
            "29ACDPN2062N1ZA\n",
            "[]\n",
            "before\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-74ed9f18db4a>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0minvoice_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minvoice_date\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mGST_Number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSupplier_Name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcapture_tax_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0mtcs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcapture_product_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m   \u001b[0mdraw_horizonatl_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_cv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minvoice_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minvoice_date\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mGST_Number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSupplier_Name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtcs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-4f929709ba1a>\u001b[0m in \u001b[0;36mdraw_horizonatl_lines\u001b[0;34m(cv2, image_cv, invoice_number, invoice_date, GST_Number, Supplier_Name, tcs, ext_name, boxes, texts, probabilities, output_filename)\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"horiz_vert\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mext_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"before\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   horiz_out = tf.image.non_max_suppression(\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mhoriz_boxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mprobabilities\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__NonMaxSuppressionV3_device_/job:localhost/replica:0/task:0/device:CPU:0}} boxes must be 2-D[0] (Shape must be rank 2 but is rank 1) [Op:NonMaxSuppressionV3]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SuUmJbDLQJBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y4edibltQJD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RJ0bbvNQQOQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n_xSHbIpQOS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xjLDP3zaRAKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JXZdd117ROFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X01x0eRORbwM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}